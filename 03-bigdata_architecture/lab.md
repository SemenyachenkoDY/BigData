# Лабораторная работа 3-1. Проектирование архитектуры хранилища больших данных

Вариант 14.

**Биотехнологическая компания:** анализ геномных
последовательностей (NGS), поиск паттернов в данных
клинических исследований, моделирование лекарственного
взаимодействия.

**Цель работы:** Разработать комплексную архитектуру хранилища больших данных для предложенного бизнес-сценария, обосновать выбор технологического стека и визуализировать потоки данных

## **Анализ требований**

1\. Объем данных

Ожидаемый объем хранения:

- Годовой объем: 500 ТБ - 2 ПБ в год
- Рост: 40-60% ежегодно
- Распределение по типам данных:
  - Медиафайлы (изображения, видео): 70% (350 ТБ - 1.4 ПБ)
  - Текстовый контент (посты, комментарии): 15% (75 ТБ - 300 ТБ)
  - Структурированные данные (лайки, метаданные, граф): 10% (50 ТБ - 200 ТБ)
  - Логи и телеметрия: 5% (25 ТБ - 100 ТБ)

**2. Скорость получения данных**

Потоковые данные (реальное время):

- Просмотры, лайки, комментарии: 10,000 - 50,000 событий/секунду
- Активность графа (подписки, добавления в друзья): 2,000 - 10,000 событий/секунду
- Телеметрия клиентов: 5,000 - 20,000 событий/секунду

Пакетные данные:

- Медиазагрузки: 500 - 2,000 файлов/минуту
- Импорт данных: ежечасно/ежедневно
- Обновления профилей: непрерывно, с пиками до 1,000 операций/секунду

**3. Типы данных**

- Структурированные данные (15%): таблицы пользователей (профили, настройки), граф социальных связей (подписки, друзья), лайки, репосты, просмотры
- Полуструктурированные (25%): API-ответы внешних сервисов, данные телеметрии приложений
- Неструктурированные (60%): тексты постов, комментарии, изображения, видео, документы, аудиосообщения.

**4. Аналитика в реальном времени:**

- контента: латентность < 100ms
- Модерация контента: латентность < 500ms
- Обновление ленты новостей: латентность < 200ms
- Обнаружение трендов: обновление каждые 5-15 минут

  Пакетная обработка (ежедневно/еженедельно):

- Пересчет графа социальных связей
- Обучение ML-моделей рекомендаций
- Анализ тональности исторических данных
- Генерация бизнес-отчетов

  Машинное обучение:

- Обучение моделей: еженедельно/ежемесячно
- Инференс: реальное время с латентностью < 300ms
- A/B тестирование алгоритмов: непрерывно

**5. Доступность данных**

  Требования к времени отклика:

- Пользовательские запросы (лента, профили): < 200ms (P95)
- Аналитические запросы: < 30 секунд для сложных агрегаций
- ML-инференс: < 500ms (P99)
- Поиск по контенту: < 1 секунда

  Доступность системы:

- Основные сервисы (лента, авторизация): 99.95% (допустимый простой ~4.3 часа/год)
- Системы хранения: 99.9% (допустимый простой ~8.8 часов/год)
- Аналитические системы: 99.5% (допустимый простой ~44 часа/год)

  RTO/RPO:

- Восстановление после сбоя (RTO): < 4 часов для критичных сервисов
- Потеря данных (RPO): < 15 минут для пользовательского контента

**6. Безопасность данных**

- TLS 1.3 для всех внешних и внутренних коммуникаций
- Шифрование данных между микросервисами
- Шифрование на уровне хранилища: AES-256 для S3-совместимых хранилищ
- Шифрование баз данных: TDE (Transparent Data Encryption)
- Управление ключами: AWS KMS / Google Cloud KMS / HashiCorp Vault
- Регулярный аудит прав доступа
- Соответствие требованиям 152-ФЗ "О персональных данных" 
- Регулярные пентесты и аудиты безопасности

**Выбор модели хранилища данных**

- MinIO - объектное хранилище (Data Lake)
- Delta Lake - табличный формат (Data Warehouse слой)
- Apache Spark - единый движок обработки

## **2. Архитектура хранилища больших данных**

**2.1. Компоненты архитектуры**

Источники данных

- Мобильное приложение (iOS/Android)
- Веб-сайт (десктопная версия)
- Внешние API (модерация контента, геолокация, погода)

Слой приема данных

- Apache Kafka - сбор всех потоковых событий (лайки, просмотры, комментарии)
- REST API - прием медиафайлов и пакетных данных

Слой хранения

- MinIO - хранение сырых данных и медиафайлов
- Delta Lake на MinIO - структурированные таблицы для аналитики
- Neo4j - графовая база для социальных связей
- PostgreSQL - метаданные пользователей и транзакционные данные

Слой оркестрации

- Apache Airflow - оркестрация рабочих процессов

Слой обработки

- Apache Flink - потоковая обработка в реальном времени
- Apache Spark - пакетная обработка и ETL

Слой машинного обучения

- ML Models - модели рекомендаций и анализа тональности
- PyTorch / TensorFlow - фреймворки машинного обучения

Слой аналитики и визуализации данных

- Jupyter Notebook - среда для аналитики
- Apache Superset - дашборды и визуализация

Слой управления данными

- OpenMetadata - каталог данных и управление метаданными
- Grafana - мониторинг системы

## **3. Схема архитектуры**

![](social_network_architecture.png)

## **4. Процесс обработки данных:**

- События из мобильного приложения и веб-сайта (лайки, просмотры, комментарии) поступают в Apache Kafka в реальном времени
- Медиафайлы (изображения, видео) загружаются напрямую в MinIO Object Storage через API-шлюз
- Данные из внешних API (модерация контента, геолокация) интегрируются через REST-коннекторы
- Оркестрация всего процесса обеспечивается Apache Airflow
- Все необработанные данные сохраняются в сыром формате в MinIO
- Потоковые данные обрабатываются в реальном времени с помощью Apache Flink
- Пакетные задачи выполняются с помощью Apache Spark
- Обогащенные данные и агрегаты сохраняются в Delta Lake для SQL-аналитики
- Актуальный граф социальных связей хранится в Neo4j для быстрого поиска связей
- Метаданные пользователей и кэшированные рекомендации сохраняются в PostgreSQL
- Модели рекомендаций обновляются ежедневно на основе свежих данных взаимодействий
- NLP-модели для анализа тональности continuously дообучаются на новых текстах
- Компьютерное зрение для анализа изображений развертывается как микросервис

## **5. Масштабирование и отказоустойчивость**

- Кластеры Kafka, Flink и Spark динамически масштабируются добавлением нод при росте нагрузки
- MinIO поддерживает распределенное развертывание на множестве серверов с автоматическим шардированием
- PostgreSQL и Neo4j работают в кластерных конфигурациях с репликацией
- Данные в MinIO защищены erasure coding с распределением по разным серверам и стойкам
- Автоматическое переключение при сбоях и health-checks всех компонентов системы

## **6. Безопасность**

- TLS/SSL для данных в движении между всеми компонентами системы
- AES-256 шифрование для данных в состоянии покоя в MinIO и базах данных
- Управление ключами шифрования через HashiCorp Vault или KMS
- OAuth 2.0 / JWT токены для аутентификации API-запросов
- Автоматическое обнаружение и классификация чувствительных данных
- Полное соответствие 152-ФЗ "О персональных данных"
- SIEM-система для обнаружения подозрительной активности в реальном времени

## **7. Анализ потенциальных проблем и их решений**

Проблема: Горячие партиции и неравномерная нагрузка в Kafka

- Риск: Перегрузка отдельных брокеров при взрывном росте активности
- Решение: Динамическое перераспределение партиций, мониторинг lag потребителей, использование ключей партиционирования по user\_id

Проблема: Быстрый рост объема данных и стоимости хранения

- Риск: Экспоненциальный рост затрат на хранение медиафайлов и логов
- Решение: Внедрение политик жизненного цикла в MinIO, архивация старых данных в холодные хранилища, компрессия и дедупликация

Проблема: Согласованность данных между разными хранилищами

- Риск: Расхождения в данных между Delta Lake, Neo4j и PostgreSQL
- Решение: Реализация идемпотентных ETL-процессов, механизм повторной обработки из Kafka, сквозная валидация данных

## **Выводы:** 
В ходе лабораторной работы была разработана архитектура хранилища данных для социальной сети. Решены ключевые задачи социальной сети: построение графа связей в Neo4j, рекомендации контента в реальном времени, анализ тональности с помощью ML-моделей. Архитектура позволяет эффективно обрабатывать большие объемы разнородных данных и поддерживает как оперативную аналитику, так и сложные ML-сценарии для улучшения пользовательского опыта




